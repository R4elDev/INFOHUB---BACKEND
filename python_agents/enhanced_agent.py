"""
üöÄ AGENTE MELHORADO COM LLMs GRATUITOS
Sistema h√≠brido que combina velocidade + intelig√™ncia artificial
"""

import time
import asyncio
from typing import Dict, Any, Optional
from smart_intent_classifier import smart_classifier
from llm_manager import llm_manager
import tools
import speed_config

class EnhancedAgent:
    def __init__(self):
        self.response_cache = {}
        self.stats = {
            "total_requests": 0,
            "cache_hits": 0,
            "quick_responses": 0,
            "llm_responses": 0,
            "avg_response_time": 0
        }
    
    async def process_message(self, user_msg: str, session_id: str, 
                            promotions_data: Optional[list] = None, 
                            user_id: Optional[int] = None) -> Dict[str, Any]:
        """
        Processa mensagem com sistema h√≠brido inteligente
        """
        start_time = time.time()
        self.stats["total_requests"] += 1
        
        try:
            # 1. Cache check ultra-r√°pido
            cache_key = f"{user_msg.lower().strip()}_{user_id or 0}"
            if cache_key in self.response_cache:
                self.stats["cache_hits"] += 1
                response = self.response_cache[cache_key].copy()
                response_time = int((time.time() - start_time) * 1000)
                response["metadata"]["response_time_ms"] = response_time
                response["metadata"]["cached"] = True
                return response
            
            # 2. Classifica√ß√£o de inten√ß√£o inteligente
            intent_result = await smart_classifier.classify_intent(user_msg, user_id)
            intent = intent_result["intent"]
            confidence = intent_result["confidence"]
            product = intent_result["product"]
            
            # 3. Processamento baseado na inten√ß√£o
            if intent in ["saudacao", "como_funciona_chat", "catalogo", "promocoes_gerais"]:
                # Respostas r√°pidas pr√©-definidas
                response = self._get_quick_response(intent, user_msg)
                self.stats["quick_responses"] += 1
                
            elif intent in ["promocao", "melhor_preco_local"] and product:
                # Busca no banco + LLM para resposta inteligente
                response = await self._get_intelligent_response(intent, product, user_msg, user_id)
                self.stats["llm_responses"] += 1
                
            else:
                # Resposta gen√©rica com LLM
                response = await self._get_llm_response(user_msg, intent)
                self.stats["llm_responses"] += 1
            
            # 4. Adiciona metadados
            response_time = int((time.time() - start_time) * 1000)
            response["metadata"] = {
                "response_time_ms": response_time,
                "cached": False,
                "agent": "enhanced",
                "intent": intent,
                "confidence": confidence,
                "method": intent_result["method"]
            }
            
            # 5. Cache para respostas boas e r√°pidas
            if response_time < 2000 and confidence > 0.7:
                self.response_cache[cache_key] = response.copy()
            
            # 6. Atualiza estat√≠sticas
            self.stats["avg_response_time"] = (self.stats["avg_response_time"] + response_time) / 2
            
            return response
            
        except Exception as e:
            print(f"‚ùå Erro no agente melhorado: {e}")
            return self._get_error_response(str(e))
    
    def _get_quick_response(self, intent: str, message: str) -> Dict[str, Any]:
        """Respostas r√°pidas pr√©-definidas"""
        responses = {
            "saudacao": {
                "reply": "üëã Ol√°! Sou seu assistente de compras inteligente. Posso te ajudar a encontrar produtos, promo√ß√µes e os melhores pre√ßos. Como posso ajudar?",
                "confidence": 0.95
            },
            
            "como_funciona_chat": {
                "reply": """ü§ñ **Como usar o InfoHub:**

üì± **Exemplos do que posso fazer:**
‚Ä¢ "leite barato" ‚Üí Encontro promo√ß√µes de leite
‚Ä¢ "farm√°cia perto" ‚Üí Melhores pre√ßos pr√≥ximos
‚Ä¢ "que produtos t√™m" ‚Üí Lista do cat√°logo
‚Ä¢ "quais as promo√ß√µes" ‚Üí Top 5 ofertas

üí° **Dicas:**
‚Ä¢ Seja espec√≠fico: "a√ß√∫car cristal" √© melhor que "a√ß√∫car"
‚Ä¢ Posso buscar por categoria: "produtos de limpeza"
‚Ä¢ Pergunto sobre localiza√ß√£o quando necess√°rio

üöÄ **Vamos come√ßar?** Digite o que procura!""",
                "confidence": 0.92
            },
            
            "catalogo": {
                "reply": self._get_catalog_response(),
                "confidence": 0.90
            },
            
            "promocoes_gerais": {
                "reply": self._get_general_promotions(),
                "confidence": 0.90
            }
        }
        
        return responses.get(intent, {
            "reply": "ü§î N√£o entendi bem. Tente perguntar sobre produtos, promo√ß√µes ou pre√ßos!",
            "confidence": 0.5
        })
    
    def _get_catalog_response(self) -> str:
        """Resposta do cat√°logo usando ferramentas existentes"""
        try:
            # Usa as ferramentas existentes para buscar produtos
            catalog_data = tools.get_available_products()
            if catalog_data and len(catalog_data) > 0:
                # Agrupa por categoria
                categories = {}
                for product in catalog_data[:20]:  # Limita para n√£o sobrecarregar
                    category = product.get('categoria', 'Outros')
                    if category not in categories:
                        categories[category] = []
                    categories[category].append(product['nome'])
                
                response = "üõí **Produtos dispon√≠veis:**\n\n"
                for category, products in categories.items():
                    response += f"**{category}:**\n"
                    for product in products[:5]:  # Max 5 por categoria
                        response += f"‚Ä¢ {product}\n"
                    response += "\n"
                
                response += "üí° **Dica:** Digite o nome do produto para ver promo√ß√µes!"
                return response
            else:
                return "üõí Cat√°logo temporariamente indispon√≠vel. Tente perguntar por produtos espec√≠ficos como 'leite', 'p√£o', 'rem√©dio', etc."
                
        except Exception as e:
            print(f"‚ùå Erro ao buscar cat√°logo: {e}")
            return "üõí Cat√°logo temporariamente indispon√≠vel. Tente perguntar por produtos espec√≠ficos!"
    
    def _get_general_promotions(self) -> str:
        """Resposta de promo√ß√µes gerais"""
        try:
            promotions = tools.get_top_promotions(limit=5)
            if promotions and len(promotions) > 0:
                response = "üî• **Top 5 Promo√ß√µes:**\n\n"
                for i, promo in enumerate(promotions, 1):
                    response += f"**{i}. {promo['produto']}**\n"
                    response += f"üí∞ R$ {promo['preco']:.2f} "
                    if promo.get('desconto'):
                        response += f"({promo['desconto']}% OFF)"
                    response += f"\nüìç {promo['loja']}\n\n"
                
                response += "üí° **Quer mais detalhes?** Digite o nome do produto!"
                return response
            else:
                return "üî• N√£o encontrei promo√ß√µes no momento. Tente buscar por produtos espec√≠ficos como 'leite barato' ou 'rem√©dio desconto'!"
                
        except Exception as e:
            print(f"‚ùå Erro ao buscar promo√ß√µes: {e}")
            return "üî• Promo√ß√µes temporariamente indispon√≠veis. Tente buscar produtos espec√≠ficos!"
    
    async def _get_intelligent_response(self, intent: str, product: str, 
                                      message: str, user_id: Optional[int]) -> Dict[str, Any]:
        """Resposta inteligente combinando dados + LLM"""
        try:
            # Busca dados no banco
            if intent == "promocao":
                data = tools.search_product_promotions(product)
            elif intent == "melhor_preco_local":
                data = tools.search_best_local_prices(product, user_id)
            else:
                data = []
            
            if not data or len(data) == 0:
                return {
                    "reply": f"üîç N√£o encontrei promo√ß√µes para '{product}' no momento. Tente:\n‚Ä¢ Verificar a grafia\n‚Ä¢ Usar termos mais gerais\n‚Ä¢ Perguntar sobre outros produtos",
                    "confidence": 0.6
                }
            
            # Formata dados para o LLM
            data_summary = self._format_data_for_llm(data, intent, product)
            
            # Prompt para o LLM
            prompt = f"""
Voc√™ √© um assistente de compras especializado. O usu√°rio perguntou: "{message}"

Dados encontrados:
{data_summary}

Crie uma resposta √∫til e bem formatada que:
1. Seja amig√°vel e direta
2. Destaque as melhores op√ß√µes (m√°ximo 3-5)
3. Inclua pre√ßos, lojas e descontos quando dispon√≠vel
4. Use emojis para tornar mais visual
5. Termine com uma dica √∫til

Mantenha a resposta concisa (m√°ximo 200 palavras).
"""
            
            llm_response = await llm_manager.get_llm_response(prompt, intent)
            
            return {
                "reply": llm_response["response"],
                "confidence": llm_response["confidence"],
                "toolsUsed": ["database_search", "llm_formatting"],
                "data_found": len(data)
            }
            
        except Exception as e:
            print(f"‚ùå Erro na resposta inteligente: {e}")
            return {
                "reply": f"üîç Encontrei informa√ß√µes sobre '{product}', mas houve um erro ao processar. Tente novamente em alguns segundos.",
                "confidence": 0.4
            }
    
    def _format_data_for_llm(self, data: list, intent: str, product: str) -> str:
        """Formata dados do banco para o LLM"""
        if not data:
            return "Nenhum dado encontrado."
        
        formatted = f"Produto: {product}\n"
        formatted += f"Resultados encontrados: {len(data)}\n\n"
        
        for i, item in enumerate(data[:5], 1):  # M√°ximo 5 itens
            formatted += f"{i}. {item.get('nome', product)}\n"
            formatted += f"   Pre√ßo: R$ {item.get('preco', 0):.2f}\n"
            formatted += f"   Loja: {item.get('loja', 'N/A')}\n"
            if item.get('desconto'):
                formatted += f"   Desconto: {item['desconto']}%\n"
            if item.get('endereco'):
                formatted += f"   Local: {item['endereco']}\n"
            formatted += "\n"
        
        return formatted
    
    async def _get_llm_response(self, message: str, intent: str) -> Dict[str, Any]:
        """Resposta gen√©rica usando LLM"""
        prompt = f"""
Voc√™ √© um assistente de compras inteligente. O usu√°rio disse: "{message}"

Inten√ß√£o detectada: {intent}

Responda de forma √∫til e amig√°vel, sugerindo como voc√™ pode ajudar com:
- Busca de produtos e promo√ß√µes
- Compara√ß√£o de pre√ßos
- Localiza√ß√£o de lojas
- Dicas de compras

Seja conciso (m√°ximo 100 palavras) e termine com uma pergunta ou sugest√£o.
"""
        
        try:
            llm_response = await llm_manager.get_llm_response(prompt, "general")
            return {
                "reply": llm_response["response"],
                "confidence": llm_response["confidence"],
                "toolsUsed": ["llm_general"]
            }
        except Exception as e:
            print(f"‚ùå Erro na resposta LLM: {e}")
            return {
                "reply": "ü§î N√£o entendi bem sua pergunta. Tente perguntar sobre produtos espec√≠ficos, promo√ß√µes ou pre√ßos!",
                "confidence": 0.3
            }
    
    def _get_error_response(self, error: str) -> Dict[str, Any]:
        """Resposta de erro padronizada"""
        return {
            "reply": "ü§î Sistema temporariamente indispon√≠vel. Tente: 'leite barato', 'farm√°cia perto' ou 'que produtos t√™m'",
            "confidence": 0.1,
            "metadata": {
                "response_time_ms": 50,
                "cached": False,
                "agent": "enhanced",
                "error": error,
                "method": "error_fallback"
            }
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """Retorna estat√≠sticas do agente"""
        return {
            **self.stats,
            "cache_size": len(self.response_cache),
            "classifier_stats": smart_classifier.get_stats(),
            "llm_status": llm_manager.get_provider_status()
        }

# Inst√¢ncia global
enhanced_agent = EnhancedAgent()
