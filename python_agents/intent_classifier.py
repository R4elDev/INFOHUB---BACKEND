"""
ü§ñ CLASSIFICADOR DE INTEN√á√ïES COM PHI-2
Sistema h√≠brido que usa LLM leve para classifica√ß√£o
"""

import requests
import json
from typing import Tuple, Dict, Any
import time

# Configura√ß√£o do Ollama
OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL = "tinydolphin:1.1b"  # Modelo mais leve e r√°pido (636MB)

# Cache de classifica√ß√µes para performance
INTENT_CACHE = {}

# Categorias de inten√ß√£o poss√≠veis
INTENT_CATEGORIES = {
    "saudacao": {
        "confidence": 0.95,
        "requires_product": False
    },
    "como_funciona_chat": {
        "confidence": 0.92,
        "requires_product": False
    },
    "ajuda": {
        "confidence": 0.90,
        "requires_product": False
    },
    "catalogo": {
        "confidence": 0.90,
        "requires_product": False
    },
    "melhor_preco_local": {
        "confidence": 0.85,
        "requires_product": True
    },
    "promocoes_gerais": {
        "confidence": 0.90,
        "requires_product": False
    },
    "promocao": {
        "confidence": 0.85,
        "requires_product": True
    },
    "outro": {
        "confidence": 0.50,
        "requires_product": False
    }
}

def classify_intent(text: str) -> Tuple[str, float]:
    """
    Classifica a inten√ß√£o do texto usando regras + LLM h√≠brido
    Retorna (intent_name, confidence)
    """
    text_clean = text.lower().strip()
    
    # Verifica cache primeiro
    if text_clean in INTENT_CACHE:
        return INTENT_CACHE[text_clean]
    
    # üöÄ CLASSIFICA√á√ÉO R√ÅPIDA COM REGRAS (0ms)
    
    # Sauda√ß√µes (alta confian√ßa)
    if any(w in text_clean for w in ['oi', 'ol√°', 'ola', 'hey', 'hello', 'bom dia', 'boa tarde', 'boa noite']):
        result = ("saudacao", 0.95)
        INTENT_CACHE[text_clean] = result
        return result
    
    # Como funciona o chat (espec√≠fico sobre funcionamento do chat/bot)
    if any(w in text_clean for w in ['como funciona o chat', 'como funciona esse chat', 'como usar o chat', 'como conversar', 'como falar com voc√™', 'como te usar', 'como usar esse bot', 'como funciona este bot']):
        result = ("como_funciona_chat", 0.92)
        INTENT_CACHE[text_clean] = result
        return result
    
    # Ajuda (alta confian√ßa)
    if any(w in text_clean for w in ['como funciona', 'ajuda', 'help', 'o que voc√™ faz', 'quem √© voc√™']):
        result = ("ajuda", 0.90)
        INTENT_CACHE[text_clean] = result
        return result
    
    # Cat√°logo (alta confian√ßa)
    if any(w in text_clean for w in ['produtos', 'cat√°logo', 'tipos', 'categorias', 'tem']):
        result = ("catalogo", 0.90)
        INTENT_CACHE[text_clean] = result
        return result
    
    # Melhor pre√ßo local (combina√ß√£o espec√≠fica)
    best_words = ['melhor', 'melhores', 'top', 'mais barato', 'menor pre√ßo']
    local_words = ['perto', 'pr√≥ximo', 'aqui perto', 'por perto']
    if any(b in text_clean for b in best_words) and any(l in text_clean for l in local_words):
        result = ("melhor_preco_local", 0.85)
        INTENT_CACHE[text_clean] = result
        return result
    
    # Localiza√ß√£o
    if any(w in text_clean for w in ['perto', 'pr√≥ximo', 'onde', 'localiza√ß√£o', 'endere√ßo']):
        result = ("local", 0.80)
        INTENT_CACHE[text_clean] = result
        return result
    
    # Promo√ß√µes gerais (quando pergunta "quais as promo√ß√µes?" sem produto)
    promocoes_gerais = ['quais as promo√ß√µes', 'que promo√ß√µes', 'promo√ß√µes dispon√≠veis', 'promo√ß√µes perto', 'ofertas dispon√≠veis', 'quais ofertas', 'ofertas perto de mim', 'ofertas pr√≥ximas', 'quais s√£o suas promo√ß√µes', 'suas promo√ß√µes', 'as promo√ß√µes']
    if any(pg in text_clean for pg in promocoes_gerais):
        result = ("promocoes_gerais", 0.90)
        INTENT_CACHE[text_clean] = result
        return result
    
    # Promo√ß√µes (palavras-chave)
    if any(w in text_clean for w in ['promo√ß√£o', 'desconto', 'oferta', 'barato', 'pre√ßo', 'cupom']):
        result = ("promocao", 0.85)
        INTENT_CACHE[text_clean] = result
        return result
    
    # ü§ñ LLM APENAS PARA CASOS AMB√çGUOS (backup)
    try:
        # Prompt ultra-simples
        prompt = f"Categorize: {text_clean}\nOptions: saudacao,ajuda,catalogo,promocao,local,outro\nAnswer:"

        payload = {
            "model": MODEL,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0,
                "top_p": 0.1,
                "num_predict": 3,
                "num_ctx": 64
            }
        }

        start_time = time.time()
        response = requests.post(OLLAMA_URL, json=payload, timeout=1.0)
        response_time = time.time() - start_time
        
        if response.status_code == 200 and response_time < 1.0:
            result_text = response.json()['response'].strip().lower()
            
            # Mapeia resultado
            for category in INTENT_CATEGORIES:
                if category in result_text:
                    confidence = INTENT_CATEGORIES[category]["confidence"] * 0.8  # Reduz por ser LLM
                    result = (category, confidence)
                    INTENT_CACHE[text_clean] = result
                    return result
    except:
        pass  # Ignora erros do LLM
    
    # üì¶ FALLBACK FINAL - sempre r√°pido
    result = ("outro", 0.5)
    INTENT_CACHE[text_clean] = result
    return result

def get_stats() -> Dict[str, Any]:
    """Retorna estat√≠sticas do classificador"""
    return {
        "model": MODEL,
        "cache_size": len(INTENT_CACHE),
        "categories": list(INTENT_CATEGORIES.keys())
    }

def clear_cache():
    """Limpa o cache de classifica√ß√µes"""
    INTENT_CACHE.clear()